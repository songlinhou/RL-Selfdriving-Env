{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DDPG Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def hidden_init(layer):\n",
    "    fan_in = layer.weight.data.size()[0]\n",
    "    lim = 1. / np.sqrt(fan_in)\n",
    "    return (-lim, lim)\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fc_units=256):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fc1_units (int): Number of nodes in first hidden layer\n",
    "            fc2_units (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "        super(Actor, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc_units)\n",
    "        self.fc2 = nn.Linear(fc_units, action_size)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fc1.weight.data.uniform_(*hidden_init(self.fc1))\n",
    "        self.fc2.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build an actor (policy) network that maps states -> actions.\"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        return F.tanh(self.fc2(x))\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    \"\"\"Critic (Value) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fcs1_units=256, fc2_units=256, fc3_units=128):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fcs1_units (int): Number of nodes in the first hidden layer\n",
    "            fc2_units (int): Number of nodes in the second hidden layer\n",
    "        \"\"\"\n",
    "        super(Critic, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fcs1 = nn.Linear(state_size, fcs1_units)\n",
    "        self.fc2 = nn.Linear(fcs1_units+action_size, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, fc3_units)\n",
    "        self.fc4 = nn.Linear(fc3_units, 1)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fcs1.weight.data.uniform_(*hidden_init(self.fcs1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(*hidden_init(self.fc3))\n",
    "        self.fc4.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        \"\"\"Build a critic (value) network that maps (state, action) pairs -> Q-values.\"\"\"\n",
    "        xs = F.leaky_relu(self.fcs1(state))\n",
    "        x = torch.cat((xs, action), dim=1)\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\30797\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "# from model import Actor, Critic\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "BUFFER_SIZE = int(1e6)  # replay buffer size\n",
    "BATCH_SIZE = 128        # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR_ACTOR = 1e-4         # learning rate of the actor \n",
    "LR_CRITIC = 3e-4        # learning rate of the critic\n",
    "WEIGHT_DECAY = 0.0001   # L2 weight decay\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Agent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "    \n",
    "    def __init__(self, state_size, action_size, random_seed):\n",
    "        \"\"\"Initialize an Agent object.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            random_seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(random_seed)\n",
    "\n",
    "        # Actor Network (w/ Target Network)\n",
    "        self.actor_local = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_target = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor_local.parameters(), lr=LR_ACTOR)\n",
    "\n",
    "        # Critic Network (w/ Target Network)\n",
    "        self.critic_local = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_target = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_optimizer = optim.Adam(self.critic_local.parameters(), lr=LR_CRITIC, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "        # Noise process\n",
    "        self.noise = OUNoise(action_size, random_seed)\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, random_seed)\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Save experience in replay memory, and use random sample from buffer to learn.\"\"\"\n",
    "        # Save experience / reward\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "\n",
    "        # Learn, if enough samples are available in memory\n",
    "        if len(self.memory) > BATCH_SIZE:\n",
    "            experiences = self.memory.sample()\n",
    "            self.learn(experiences, GAMMA)\n",
    "\n",
    "    def act(self, state, add_noise=True):\n",
    "        \"\"\"Returns actions for given state as per current policy.\"\"\"\n",
    "        state = torch.from_numpy(state).float().to(device)\n",
    "        self.actor_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action = self.actor_local(state).cpu().data.numpy()\n",
    "        self.actor_local.train()\n",
    "        if add_noise:\n",
    "            action += self.noise.sample()\n",
    "        return np.clip(action, -1, 1)\n",
    "\n",
    "    def reset(self):\n",
    "        self.noise.reset()\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"Update policy and value parameters using given batch of experience tuples.\n",
    "        Q_targets = r + γ * critic_target(next_state, actor_target(next_state))\n",
    "        where:\n",
    "            actor_target(state) -> action\n",
    "            critic_target(state, action) -> Q-value\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # ---------------------------- update critic ---------------------------- #\n",
    "        # Get predicted next-state actions and Q values from target models\n",
    "        actions_next = self.actor_target(next_states)\n",
    "        Q_targets_next = self.critic_target(next_states, actions_next)\n",
    "        # Compute Q targets for current states (y_i)\n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "        # Compute critic loss\n",
    "        Q_expected = self.critic_local(states, actions)\n",
    "        critic_loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        # Minimize the loss\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "        # ---------------------------- update actor ---------------------------- #\n",
    "        # Compute actor loss\n",
    "        actions_pred = self.actor_local(states)\n",
    "        actor_loss = -self.critic_local(states, actions_pred).mean()\n",
    "        # Minimize the loss\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # ----------------------- update target networks ----------------------- #\n",
    "        self.soft_update(self.critic_local, self.critic_target, TAU)\n",
    "        self.soft_update(self.actor_local, self.actor_target, TAU)                     \n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            local_model: PyTorch model (weights will be copied from)\n",
    "            target_model: PyTorch model (weights will be copied to)\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
    "\n",
    "class OUNoise:\n",
    "    \"\"\"Ornstein-Uhlenbeck process.\"\"\"\n",
    "\n",
    "    def __init__(self, size, seed, mu=0., theta=0.15, sigma=0.2):\n",
    "        \"\"\"Initialize parameters and noise process.\"\"\"\n",
    "        self.mu = mu * np.ones(size)\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.seed = random.seed(seed)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the internal state (= noise) to mean (mu).\"\"\"\n",
    "        self.state = copy.copy(self.mu)\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
    "        x = self.state\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.array([random.random() for i in range(len(x))])\n",
    "        self.state = x + dx\n",
    "        return self.state\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "        Params\n",
    "        ======\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  # internal memory (deque)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "\n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actor(\n",
       "  (fc1): Linear(in_features=34, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Actor(state_size=env.observation_space.shape[0], action_size=env.action_space.shape[0], seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Critic(\n",
       "  (fcs1): Linear(in_features=34, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=258, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc4): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Critic(state_size=env.observation_space.shape[0], action_size=env.action_space.shape[0], seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlagents_envs.environment import UnityEnvironment\n",
    "from gym_unity.envs import UnityToGymWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_path = 'C:/Users/30797/UnitySpace/RLCar/build/RLCar.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'game_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f19d4033a467>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0munity_env\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnityEnvironment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# unity_env = UnityEnvironment(base_port=5004)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnityToGymWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munity_env\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'game_path' is not defined"
     ]
    }
   ],
   "source": [
    "unity_env = UnityEnvironment(game_path)\n",
    "# unity_env = UnityEnvironment(base_port=5004)\n",
    "\n",
    "env = UnityToGymWrapper(unity_env, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "revised_ob_space = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size=env.observation_space.shape[0], action_size=env.action_space.shape[0], random_seed=10)\n",
    "# agent = Agent(state_size=revised_ob_space, action_size=env.action_space.shape[0], random_seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 0.        , 0.6383529 , 0.        ,\n",
       "       0.50771314, 0.        , 0.34760505, 0.        , 0.2764671 ,\n",
       "       0.        , 0.26906538, 0.        , 0.21400076, 0.7071068 ,\n",
       "       0.7071068 , 0.9999567 , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# idx = [1,3,5,7,9,11,13,14,15,16,17,18]\n",
    "# state2 = state[idx]\n",
    "# len(state2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_states():\n",
    "    torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "    torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "    print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "    \n",
    "# def filter_state(state):\n",
    "#     idx = [1,3,5,7,9,11,13,14]\n",
    "#     state2 = state[idx]\n",
    "#     return state2\n",
    "\n",
    "def filter_state(state):\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\30797\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.08022818, 0.09354205], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter_state(state)\n",
    "action = agent.act(state)\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd9851f969748b3b35dc548732cbdca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5\tAverage Score: -156.00\tScore: -470.00\n",
      "Episode 10\tAverage Score: -183.00\tScore: 100.00\n",
      "Episode 15\tAverage Score: -32.00\tScore: 1110.00\n",
      "Episode 20\tAverage Score: 130.50\tScore: 190.000\n",
      "Episode 25\tAverage Score: 122.80\tScore: 220.000\n",
      "Episode 30\tAverage Score: 282.67\tScore: 1180.00\n",
      "Episode 35\tAverage Score: 383.14\tScore: 270.000\n",
      "Episode 40\tAverage Score: 344.00\tScore: 50.000\n",
      "Episode 45\tAverage Score: 297.33\tScore: -200.00\n",
      "Episode 50\tAverage Score: 266.40\tScore: 100.000\n",
      "Episode 55\tAverage Score: 251.27\tScore: 100.00\n",
      "Episode 60\tAverage Score: 227.67\tScore: -460.00\n",
      "Episode 65\tAverage Score: 214.62\tScore: 40.000\n",
      "Episode 70\tAverage Score: 202.43\tScore: 50.00\n",
      "Episode 75\tAverage Score: 186.40\tScore: -230.00\n",
      "Episode 80\tAverage Score: 166.12\tScore: -10.000\n",
      "Episode 85\tAverage Score: 148.94\tScore: -350.00\n",
      "Episode 90\tAverage Score: 116.78\tScore: -650.00\n",
      "Episode 95\tAverage Score: 98.63\tScore: -370.000\n",
      "Episode 98\tAverage Score: 84.18\tScore: -370.00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-c17173c9e90f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mddpg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-80-c17173c9e90f>\u001b[0m in \u001b[0;36mddpg\u001b[1;34m(n_episodes, max_t)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mnext_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#             print(len(next_state))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-5cb158df9c70>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# Learn, if enough samples are available in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mexperiences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGAMMA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-5cb158df9c70>\u001b[0m in \u001b[0;36msample\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[1;34m\"\"\"Randomly sample a batch of experiences from memory.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m         \u001b[0mexperiences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\random.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, population, k)\u001b[0m\n\u001b[0;32m    339\u001b[0m                     \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandbelow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mselected_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                 \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores, avg_scores = [],[]\n",
    "def ddpg(n_episodes=2000, max_t=11000):\n",
    "    scores_deque = deque(maxlen=200)\n",
    "    scores = []\n",
    "    max_score = -np.Inf\n",
    "    for i_episode in tqdm(range(1, n_episodes+1)):\n",
    "        state = env.reset()\n",
    "        state = filter_state(state)\n",
    "        agent.reset()\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "#             print(len(state))\n",
    "            if(state[-1] == 0):\n",
    "                action = np.array([0,0])\n",
    "            else:\n",
    "                action = agent.act(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            next_state = filter_state(next_state)\n",
    "#             print(len(next_state))\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_deque.append(score)\n",
    "        scores.append(score)\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}\\tScore: {:.2f}'.format(i_episode, np.mean(scores_deque), score), end=\"\")\n",
    "        if i_episode % 5 == 0:\n",
    "            torch.save(agent.actor_local.state_dict(), f'checkpoint_actor_3_E{i_episode}_S{score}.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), f'checkpoint_critic_3_E{i_episode}_S{score}.pth')\n",
    "            scores.append(score)\n",
    "            avg_scores.append(np.mean(scores_deque))\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))   \n",
    "    return scores\n",
    "\n",
    "scores = ddpg()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnityEnvironmentException",
     "evalue": "No Unity environment is loaded.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnityEnvironmentException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-1baceacf4cb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gym_unity\\envs\\__init__.py\u001b[0m in \u001b[0;36mclose\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[0mgarbage\u001b[0m \u001b[0mcollected\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprogram\u001b[0m \u001b[0mexits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \"\"\"\n\u001b[1;32m--> 271\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlagents_envs\\environment.py\u001b[0m in \u001b[0;36mclose\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_close\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mUnityEnvironmentException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No Unity environment is loaded.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_close\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnityEnvironmentException\u001b[0m: No Unity environment is loaded."
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1) * 5, scores, label='score')\n",
    "plt.plot(np.arange(1, len(avg_scores)+1) * 5, avg_scores, label='avg_score')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-08 20:09:06 INFO [environment.py:205] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.\n",
      "2020-12-08 20:09:16 WARNING [environment.py:104] WARNING: The communication API versions between Unity and python differ at the minor version level. Python API: 1.2.0, Unity API: 1.0.\n",
      "This means that some features may not work unless you upgrade the package with the lower version.Please find the versions that work best together from our release page.\n",
      "https://github.com/Unity-Technologies/ml-agents/releases\n",
      "2020-12-08 20:09:16 INFO [environment.py:271] Connected new brain:\n",
      "My Behavior?team=0\n",
      "2020-12-08 20:09:16 WARNING [__init__.py:92] The environment contains multiple observations. You must define allow_multiple_obs=True to receive them all. Otherwise, only the first visual observation (or vector observation ifthere are no visual observations) will be provided in the observation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score= 1360.0\n"
     ]
    }
   ],
   "source": [
    "# test run\n",
    "\n",
    "def ddpg_eval():\n",
    "    agent = Agent(state_size=env.observation_space.shape[0], action_size=env.action_space.shape[0], random_seed=10)\n",
    "#     agent = Agent(state_size=env.observation_space.shape[0], action_size=env.action_space.shape[0], random_seed=30)\n",
    "\n",
    "    agent.actor_local.load_state_dict(torch.load('checkpoint_actor_3_E30_S1180.0.pth'))\n",
    "    agent.critic_local.load_state_dict(torch.load('checkpoint_critic_3_E30_S1180.0.pth'))\n",
    "    \n",
    "#     agent.actor_local.load_state_dict(torch.load('checkpoint_actor_3_E15_S1110.0.pth'))\n",
    "#     agent.critic_local.load_state_dict(torch.load('checkpoint_critic_3_E15_S1110.0.pth'))\n",
    "\n",
    "\n",
    "    state = env.reset()\n",
    "    state = filter_state(state)\n",
    "    agent.reset()\n",
    "    score = 0\n",
    "    max_t = 10000\n",
    "    for t in range(max_t):\n",
    "        if(state[-1] == 0):\n",
    "            action = np.array([0,0])\n",
    "        else:\n",
    "            action = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        next_state = filter_state(next_state)\n",
    "        state = next_state\n",
    "        score += reward\n",
    "        if done:\n",
    "            break \n",
    "    print(\"score=\", score)\n",
    "    \n",
    "env = UnityToGymWrapper(UnityEnvironment(base_port=5004), 0)\n",
    "# env = UnityToGymWrapper(UnityEnvironment(game_path), 0)\n",
    "ddpg_eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
